{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36015802",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/miniconda3/envs/vr/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "from PIL import Image\n",
    "import io\n",
    "import time\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "748f84a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_df = pd.read_csv('dataset/images.csv')\n",
    "metadata_lookup = {}\n",
    "json_files = sorted(glob.glob('dataset/listings/metadata/listings_*.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fae34b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_df = images_df.drop(columns=['height','width']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "959a78f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>010-mllS7JL</td>\n",
       "      <td>14/14fe8812.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01dkn0Gyx0L</td>\n",
       "      <td>da/daab0cad.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01sUPg0387L</td>\n",
       "      <td>d2/d2daaae9.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1168jc-5r1L</td>\n",
       "      <td>3a/3a4e88e6.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11RUV5Fs65L</td>\n",
       "      <td>d9/d91ab9cf.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398207</th>\n",
       "      <td>B1zv8OpTkBS</td>\n",
       "      <td>6d/6d49d130.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398208</th>\n",
       "      <td>B1zwflWhPIS</td>\n",
       "      <td>b1/b163e0ea.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398209</th>\n",
       "      <td>C1lf45DhhRS</td>\n",
       "      <td>a1/a116d9d1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398210</th>\n",
       "      <td>C1pEt6jBLiS</td>\n",
       "      <td>9c/9c3e1158.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398211</th>\n",
       "      <td>C1sCYAz8NAS</td>\n",
       "      <td>cf/cf112e38.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>398212 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           image_id             path\n",
       "0       010-mllS7JL  14/14fe8812.jpg\n",
       "1       01dkn0Gyx0L  da/daab0cad.jpg\n",
       "2       01sUPg0387L  d2/d2daaae9.jpg\n",
       "3       1168jc-5r1L  3a/3a4e88e6.jpg\n",
       "4       11RUV5Fs65L  d9/d91ab9cf.jpg\n",
       "...             ...              ...\n",
       "398207  B1zv8OpTkBS  6d/6d49d130.jpg\n",
       "398208  B1zwflWhPIS  b1/b163e0ea.jpg\n",
       "398209  C1lf45DhhRS  a1/a116d9d1.jpg\n",
       "398210  C1pEt6jBLiS  9c/9c3e1158.jpg\n",
       "398211  C1sCYAz8NAS  cf/cf112e38.jpg\n",
       "\n",
       "[398212 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59152c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_field(data, key, inner_key='value'):\n",
    "    if isinstance(data.get(key), list) and data[key]:\n",
    "        first = data[key][0]\n",
    "        if 'language_tag' in first and not first['language_tag'].startswith('en_'):\n",
    "            return None\n",
    "        return first.get(inner_key, None)\n",
    "    return None\n",
    "\n",
    "def extract_keywords(data):\n",
    "    if isinstance(data.get('item_keywords'), list):\n",
    "        keywords = [\n",
    "            k['value'].strip().lower()\n",
    "            for k in data['item_keywords']\n",
    "            if 'language_tag' not in k or k['language_tag'].startswith('en_')\n",
    "        ]\n",
    "        seen = set()\n",
    "        deduped_keywords = [k for k in keywords if not (k in seen or seen.add(k))]\n",
    "        return ', '.join(deduped_keywords)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03cb9c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building metadata lookup from JSON files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing listings JSONs:   0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing listings JSONs: 100%|██████████| 16/16 [00:23<00:00,  1.48s/it]\n"
     ]
    }
   ],
   "source": [
    "print(\"Building metadata lookup from JSON files...\")\n",
    "for file in tqdm(json_files, desc=\"Parsing listings JSONs\"):\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                record = json.loads(line.strip())\n",
    "                main_id = record.get('main_image_id', None)\n",
    "                if main_id:\n",
    "                    name = extract_field(record, 'item_name')\n",
    "                    category = extract_field(record, 'product_type')\n",
    "                    # brand = extract_field(record, 'brand')\n",
    "                    color = extract_field(record, 'color')\n",
    "                    keywords = extract_keywords(record)\n",
    "                    metadata_lookup[main_id] = {\n",
    "                        'name': name,\n",
    "                        'category': category,\n",
    "                        # 'brand': brand,\n",
    "                        'color': color,\n",
    "                        'keywords': keywords\n",
    "                    }\n",
    "            except json.JSONDecodeError:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60ae71cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata(image_id, field):\n",
    "    data = metadata_lookup.get(image_id)\n",
    "    if not data:\n",
    "        return None\n",
    "    return data.get(field, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6470823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata(image_id, field):\n",
    "    data = metadata_lookup.get(image_id)\n",
    "    if not data:\n",
    "        return None\n",
    "    return data.get(field, None)\n",
    "\n",
    "tqdm.pandas(desc=\"Matching image_ids\")\n",
    "images_df['name'] = images_df['image_id'].progress_apply(lambda x: get_metadata(x, 'name'))\n",
    "images_df['category'] = images_df['image_id'].progress_apply(lambda x: get_metadata(x, 'category'))\n",
    "# images_df['brand'] = images_df['image_id'].progress_apply(lambda x: get_metadata(x, 'brand'))\n",
    "images_df['color'] = images_df['image_id'].progress_apply(lambda x: get_metadata(x, 'color'))\n",
    "images_df['keywords'] = images_df['image_id'].progress_apply(lambda x: get_metadata(x, 'keywords'))\n",
    "\n",
    "def is_ascii(text):\n",
    "    try:\n",
    "        if pd.isnull(text):\n",
    "            return False\n",
    "        text.encode('ascii')\n",
    "        return True\n",
    "    except UnicodeEncodeError:\n",
    "        return False\n",
    "\n",
    "print(\"Applying filters...\")\n",
    "images_df.dropna(subset=['name', 'category', 'color'], inplace=True)\n",
    "for col in ['name', 'category', 'color']:\n",
    "    images_df = images_df[images_df[col].apply(is_ascii)]\n",
    "\n",
    "# images_df.to_csv('data/cleaned.csv', index=False)\n",
    "print(f\"Saved final filtered dataset to curated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1a77849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GOOGLE_API_KEY = \"AIzaSyAwziGqosd-np08NVMj6gEUylCS0Yc3kyE\" #ananthakk26@gmail.com = My First Project (312)\n",
    "# GOOGLE_API_KEY = \"AIzaSyDDpeIrrCT-6uzFmyhIiVIHX3mXRUsTBNQ\"  #zebramee1@gmail.com = vr-1 (1397)\n",
    "# GOOGLE_API_KEY = \"AIzaSyCSuPjNooXxuFmfwRMBG9KZH5tJARSqc5Y\"  #zebramee1@gmail.com = vr-2 (1450)\n",
    "# GOOGLE_API_KEY = \"AIzaSyA0UhYe9svadSKOd0niUcMV86cCfynDGsI\"  #zebramee1@gmail.com = vr-3 (1480)\n",
    "# GOOGLE_API_KEY = \"AIzaSyCB0PmIHRxMQn_y9-L0uBonlEfEJ9ojUwc\"  #zebramee1@gmail.com = vr-4 (1470)\n",
    "# GOOGLE_API_KEY = \"AIzaSyDi3ylfG9Fnpbcf5nq8D9L4V1xwrGAymew\"  #zebramee1@gmail.com = vr-5 (done)\n",
    "# GOOGLE_API_KEY = \"AIzaSyB7nGzvNvfEAShgxa1X6ywsyO1b7xeq54s\"  #zebramee1@gmail.com = vr-6 (1490)\n",
    "GOOGLE_API_KEY = \"AIzaSyBoIpoLyA8VWVGcMvYSEwk740ZEGj01aIE\"  #zebramee1@gmail.com = vr-7 (0)\n",
    "# GOOGLE_API_KEY = \"AIzaSyAhMC1sVMVEQJ4EUKLyWAC0y_2k6iTkV5Q\"  #zebramee1@gmail.com = vr-8 (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a28d89c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "generation_config = {\n",
    "  \"temperature\": 0.5, # Lower temperature for more factual/constrained answers\n",
    "  \"top_p\": 1,\n",
    "  \"top_k\": 32,\n",
    "  \"max_output_tokens\": 2000, # Sufficient for a Q&A pair\n",
    "}\n",
    "\n",
    "model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\",generation_config=generation_config,)\n",
    "IMAGE_SUBDIRECTORY = \"dataset/small\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54607d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Function to generate MULTIPLE Q&A pairs in ONE call ---\n",
    "# Takes the FULL path to the image now\n",
    "def generate_multiple_qa_for_image(full_image_path, metadata_without_brand):\n",
    "    \"\"\"\n",
    "    Asks Gemini to generate 5 distinct Q&A pairs for an image in a single API call.\n",
    "\n",
    "    Args:\n",
    "        full_image_path (str): The complete path to the image file (including subdirectory).\n",
    "        metadata_without_brand (dict): Dictionary containing metadata (excluding 'brand').\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples, where each tuple is (question, answer).\n",
    "              Returns an empty list if generation or parsing fails.\n",
    "    \"\"\"\n",
    "    generated_pairs = []\n",
    "    try:\n",
    "        # Use the full_image_path passed to the function\n",
    "        img = Image.open(full_image_path)\n",
    "    except FileNotFoundError:\n",
    "        # This error message now shows the full path it tried\n",
    "        print(f\"Error: Image file not found at {full_image_path}\")\n",
    "        return generated_pairs\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening image {full_image_path}: {e}\")\n",
    "        return generated_pairs\n",
    "\n",
    "    # --- Prompt (remains the same) ---\n",
    "    prompt_parts = [\n",
    "        \"Context about the image, make sure to also look at the image and analyse it before generating :\",\n",
    "        f\"- Name: {metadata_without_brand.get('name', 'N/A')}\",\n",
    "        f\"- Category: {metadata_without_brand.get('category', 'N/A')}\",\n",
    "        f\"- Main Color Provided: {metadata_without_brand.get('color', 'N/A')}\",\n",
    "        f\"- Keywords: {metadata_without_brand.get('keywords', 'N/A')}\\n\",\n",
    "        \"Instructions:\",\n",
    "        \"1. Analyze the provided image and the context.\",\n",
    "        \"2. Generate exactly 5 (five) distinct questions about prominent visual features, objects, colors, materials, or attributes clearly visible in the image.\",\n",
    "        \"3. Each question MUST have a single-word answer directly verifiable from the image.\",\n",
    "        \"4. The 5 questions generated MUST be different from each other, and make sure that the questions are answerable just by looking at the image for exmaple do nt ask questions like brand, if it there in the metadata but not in the image, and make the questions EASY\",\n",
    "        \"5. Provide the output strictly in the following numbered format, with each question and answer pair clearly marked. Do not include any other text before or after this numbered list:\\n\",\n",
    "        \"6. Remember to make the questions easy and answerable just by loking at the image, like color shape etc\",\n",
    "        \"\"\"1.\n",
    "Question 1: [Your first question here]\n",
    "Answer 1: [Your single-word answer here]\n",
    "2.\n",
    "Question 2: [Your second question here]\n",
    "Answer 2: [Your single-word answer here]\n",
    "3.\n",
    "Question 3: [Your third question here]\n",
    "Answer 3: [Your single-word answer here]\n",
    "4.\n",
    "Question 4: [Your fourth question here]\n",
    "Answer 4: [Your single-word answer here]\n",
    "5.\n",
    "Question 5: [Your fifth question here]\n",
    "Answer 5: [Your single-word answer here]\"\"\",\n",
    "        \"\\nImage:\",\n",
    "        img,\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        time.sleep(2.55)\n",
    "        # Pass the full_image_path in the print statement for clarity\n",
    "        # print(f\"  Sending prompt to Gemini for image: {full_image_path}\")\n",
    "        response = model.generate_content(prompt_parts)\n",
    "        response_text = response.text.strip()\n",
    "        # print(f\"  Received response text (length: {len(response_text)} chars).\")\n",
    "\n",
    "        # --- Parsing the response (remains the same) ---\n",
    "        pattern = re.compile(\n",
    "            r\"^\\s*\\d+\\.\\s*\\nQuestion\\s*\\d*:\\s*(.*?)\\s*\\nAnswer\\s*\\d*:\\s*(\\w+)\",\n",
    "            re.MULTILINE | re.IGNORECASE\n",
    "        )\n",
    "        matches = pattern.findall(response_text)\n",
    "\n",
    "        if matches:\n",
    "            # print(f\"  Successfully parsed {len(matches)} Q&A pairs.\")\n",
    "            for q, a in matches:\n",
    "                question = q.strip().rstrip('?.!')\n",
    "                answer = a.strip().lower()\n",
    "                if question and answer:\n",
    "                    generated_pairs.append((question, answer))\n",
    "            if len(generated_pairs) < 5:\n",
    "                 print(f\"  Warning: Parsed fewer than 5 Q&A pairs ({len(generated_pairs)}).\")\n",
    "        else:\n",
    "            print(f\"  Warning: Could not parse Q&A pairs using regex. Check response format.\")\n",
    "            print(f\"  Response Text was:\\n{response_text[:500]}...\")\n",
    "\n",
    "    except Exception as e:\n",
    "        # Pass the full_image_path in the error message\n",
    "        print(f\"Error during Gemini API call or processing for {full_image_path}: {e}\")\n",
    "        try:\n",
    "            if response and response.prompt_feedback:\n",
    "                print(f\"Prompt Feedback: {response.prompt_feedback}\")\n",
    "            if response and not response.candidates:\n",
    "                 print(\"Warning: Response has no candidates.\")\n",
    "            elif response and response.candidates and not response.candidates[0].content:\n",
    "                 print(\"Warning: Received empty response content.\")\n",
    "        except Exception as feedback_err:\n",
    "            print(f\"(Error retrieving feedback: {feedback_err})\")\n",
    "\n",
    "    return generated_pairs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aeb62156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating image paths in 'dataset/small/'...\n",
      "Found 76017 valid image paths out of 76017 total rows.\n"
     ]
    }
   ],
   "source": [
    "# --- Main Logic ---\n",
    "all_generated_qa_data = []\n",
    "\n",
    "# --- Path Validation ---\n",
    "# Filter using the SUBDIRECTORY\n",
    "print(f\"Validating image paths in '{IMAGE_SUBDIRECTORY}/'...\")\n",
    "original_count = len(images_df)\n",
    "# Drop rows where path is NaN or None first\n",
    "images_df_cleaned = images_df.dropna(subset=['path']).copy()\n",
    "# Check existence by joining the subdirectory with the relative path\n",
    "valid_images_df = images_df_cleaned[images_df_cleaned['path'].apply(\n",
    "    lambda relative_path: os.path.exists(os.path.join(IMAGE_SUBDIRECTORY, relative_path))\n",
    ")].copy() # Ensure it's a copy\n",
    "\n",
    "print(f\"Found {len(valid_images_df)} valid image paths out of {original_count} total rows.\")\n",
    "\n",
    "if len(valid_images_df) == 0:\n",
    "    print(f\"Error: No valid image paths found in '{IMAGE_SUBDIRECTORY}/' based on the 'path' column. Please check the paths and subdirectory name.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4f286a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# done till 0,1...2849 in curated.csv \n",
    "# done till 0,1,...2958 in non_case.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "339cd66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing index 656 (Item 1/1) | Image ID: 21QA1aaQcsL | Path: dataset/small/1e/1e00bd6c.jpg...\n",
      "  -> Adding 5 generated Q&A pairs for 21QA1aaQcsL.\n"
     ]
    }
   ],
   "source": [
    "df_to_process = valid_images_df.iloc[0:1]\n",
    "\n",
    "# --- Loop through the SELECTED SLICE ---\n",
    "processed_count = 0\n",
    "for index, row in df_to_process.iterrows(): # Iterate over the slice\n",
    "    image_id = row['image_id']\n",
    "    relative_path = str(row['path']) # Ensure path is string\n",
    "\n",
    "    # --- Construct the FULL path ---\n",
    "    full_image_path = os.path.join(IMAGE_SUBDIRECTORY, relative_path)\n",
    "\n",
    "    # Print progress relative to the slice being processed\n",
    "    print(f\"\\nProcessing index {index} (Item {processed_count + 1}/{len(df_to_process)}) | Image ID: {image_id} | Path: {full_image_path}...\")\n",
    "\n",
    "    metadata_for_prompt = row.to_dict()\n",
    "    metadata_for_prompt.pop('path', None)\n",
    "\n",
    "    # --- Make ONE API call per image using the FULL path ---\n",
    "    qa_pairs_for_image = generate_multiple_qa_for_image(full_image_path, metadata_for_prompt)\n",
    "\n",
    "    if qa_pairs_for_image:\n",
    "        print(f\"  -> Adding {len(qa_pairs_for_image)} generated Q&A pairs for {image_id}.\")\n",
    "        # Add each generated pair as a separate entry\n",
    "        for i, (question, answer) in enumerate(qa_pairs_for_image):\n",
    "            all_generated_qa_data.append({\n",
    "                'image_id': image_id,\n",
    "                'image_path': full_image_path,\n",
    "                'question': question,\n",
    "                'answer': answer\n",
    "            })\n",
    "    else:\n",
    "        print(f\"  -> Failed to generate/parse any Q&A pairs for {image_id}.\")\n",
    "        break\n",
    "\n",
    "    processed_count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b8a702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Finished processing all images ---\n",
      "Generated a total of 5 Q&A pairs.\n",
      "\n",
      "Generated Q&A Dataset:\n",
      "      image_id                     image_path  \\\n",
      "0  21QA1aaQcsL  dataset/small/1e/1e00bd6c.jpg   \n",
      "1  21QA1aaQcsL  dataset/small/1e/1e00bd6c.jpg   \n",
      "2  21QA1aaQcsL  dataset/small/1e/1e00bd6c.jpg   \n",
      "3  21QA1aaQcsL  dataset/small/1e/1e00bd6c.jpg   \n",
      "4  21QA1aaQcsL  dataset/small/1e/1e00bd6c.jpg   \n",
      "\n",
      "                                 question       answer  \n",
      "0     What is the main color of the cable        black  \n",
      "1           What shape are the connectors  rectangular  \n",
      "2           How many connectors are there          two  \n",
      "3   What type of connector is on the left         hdmi  \n",
      "4  What type of connector is on the right  displayport  \n",
      "\n",
      "Results saved to qna.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Processing Finished ---\n",
    "print(f\"\\n--- Finished processing all images ---\")\n",
    "print(f\"Generated a total of {len(all_generated_qa_data)} Q&A pairs.\")\n",
    "\n",
    "# --- Create the final dataset ---\n",
    "if all_generated_qa_data:\n",
    "    qa_results_df = pd.DataFrame(all_generated_qa_data)\n",
    "    print(\"\\nGenerated Q&A Dataset:\")\n",
    "    with pd.option_context('display.max_rows', 20, 'display.max_colwidth', 80):\n",
    "        print(qa_results_df)\n",
    "\n",
    "    try:\n",
    "        qa_results_df.to_csv(\"data/qna.csv\", index=False)\n",
    "        print(\"\\nResults saved to qna.csv\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError saving results to CSV: {e}\")\n",
    "else:\n",
    "    print(\"\\nNo Q&A pairs were successfully generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbae280",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
